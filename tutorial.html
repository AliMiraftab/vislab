<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <title>Vislab | Tutorial</title>

    <link rel="stylesheet" href="css/style.css">
    <link rel="stylesheet" href="//netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css">
    <script src="//ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <script type="text/javascript" src="//use.typekit.net/uzs7hgs.js"></script>
    <script type="text/javascript">try{Typekit.load();}catch(e){}</script>
  </head>
  <body>
    
    <header>
      <a href="/"><i class="fa fa-th"></i> Vislab</a>
    </header>
    
    <section>
      <h1 id="tutorial">Tutorial</h1>

<h2 id="setting_up">Setting up</h2>

<p>VisLab has the following external dependencies:</p>

<ul>
<li><a href="https://www.mongodb.org/">MongoDB</a>: key-value store used for storing features</li>

<li><a href="http://redis.io/">Redis</a>: key-value store used for our job queue</li>

<li><a href="https://github.com/JohnLangford/vowpal_wabbit">Vowpal Wabbit</a>: machine learning framework</li>

<li>and a bunch of Python packages: we recommend using the <a href="https://store.continuum.io/cshop/anaconda/">Anaconda distribution</a>, which provides most of them out of the box.</li>

<li>some Matlab code for feature computation is required if you’re not satisfied with the convolutional network feature.</li>
</ul>
<!-- - [Caffe] deep-learning framework (another Berkeley project)
    Caffe itself has many dependencies, such as OpenCV.
 -->
<p>Additionally, you’ll benefit from downloading our pre-packaged datasets. Follow along for the link.</p>

<h2 id="installing_dependencies">Installing dependencies</h2>

<p>We’re going to describe the setup on OS X (tested with versions 10.8 and above).</p>

<p><a href="http://brew.sh/">Homebrew</a> is by far the best way to manage packages on OS X, so we assume that it is used. On Linux, most <code>brew install</code> commands can be replaced with <code>sudo apt-get install</code>.</p>

<p>We also assume that the <a href="https://store.continuum.io/cshop/anaconda/">Anaconda distribution</a> of Python is used. If not, no problem: simply replace <code>conda install</code> with <code>pip install</code> – but you will need to install <em>many</em> additional packages, such as ‘numpy’, yourself.</p>

<p>First, external dependencies.</p>

<pre><code>brew install mongo
brew install redis
brew install fftw
brew install parallel
brew install boost</code></pre>

<p>Now the Python package dependencies.</p>

<pre><code>conda install pymongo
conda install pyleargist
conda install joblib
conda install rq
conda install husl</code></pre>

<p>A little trick is needed for openmpi:</p>

<pre><code>conda remove openmpi
brew install openmpi
conda install mpi4py</code></pre>

<p>Clone and install Vowpal Wabbit.</p>

<pre><code>git clone git@github.com:JohnLangford/vowpal_wabbit.git
cd vowpal_wabbit
make
make install</code></pre>
<!-- To install [Caffe][], please follow the [instructions](http://caffe.berkeleyvision.org/installation.html). -->
<h3 id="getting_vislab_code_and_wikipaintings_dataset">Getting vislab code and wikipaintings dataset</h3>

<p>You’ll need to pick a work directory that will contain the repository. I use <code>~/work</code>, so this repository goes into <code>~/work/vislab-git</code>.</p>

<pre><code>mkdir ~/work
cd ~/work
git clone https://github.com/sergeyk/vislab.git vislab-git</code></pre>

<p>Set up the Python path to contain this directory:</p>

<pre><code>export PYTHONPATH=$HOME/work/vislab-git:$PYTHONPATH</code></pre>

<p><em>All following commmands assume that you are performing them in this directory.</em></p>

<h2 id="simple_experiment">Simple experiment</h2>

<p>Now let’s run a classification experiment on the Wikipaintings dataset.</p>

<h4 id="assembling_the_dataset">Assembling the dataset</h4>

<p>First order of business is assembling the dataset. Originally, this involved scraping ~100K records from the Wikipaintings.org website. No one should have to do that more than once, so simply download our pre-packaged data from this <a href="https://www.dropbox.com/sh/our2zcaaqfi2e6d/1rZs5J4xhl">Dropbox folder</a>. Copy the whole thing to <code>vislab-git/data/shared</code> – or simply symlink directly to the dropbox directory:</p>

<pre><code>mkdir data
ln -s ~/Dropbox/vislab_data_shared data/shared</code></pre>

<p>Next, copy over the default configuration.</p>

<pre><code>cp vislab/config.json.example vislab/config.json</code></pre>

<p>Edit <code>config.json</code> to point to the folders for your local installation (the defaults should work if you’ve followed the instructions so far).</p>

<p>To use a lot of the functionality of the dataset, we need to start a MongoDB server. In another shell, run</p>

<pre><code>./scripts/start_mongo.sh</code></pre>

<p>This will launch a server on port <code>27666</code>, which is canonically expected by the rest of the code. You can ignore any errors about <code>numactl</code> being missing; don’t worry, that only plays a role for our cluster setup. MongoDB is used for storing image information, features, and classification results.</p>

<p>To check that you can load the dataset, open another terminal and fire up IPython Notebook:</p>

<pre><code>ipython notebook --pylab=inline notebooks</code></pre>

<p>This should open a browser, where you can select the ‘wikipaintings dataset’ notebook. Run the cells in it to make sure that the data quickly loads and works as expected. If python complains about being unable to import packages, <code>conda install</code> or <code>pip install</code> them as needed.</p>

<p>Note: if the cell with <code>df = wikipaintings.get_basic_df()</code> doesn’t complete within a few seconds, then the data wasn’t found; check that you have correctly set the paths in <code>config.json</code>.</p>

<h3 id="computing_features_on_a_dataset">Computing features on a dataset</h3>

<p>The first step to classifying the dataset is computing some features on the images. The dataset does not contain images, they will be downloaded as needed by the feature computation code.</p>

<p>For this demo, we won’t actually look at the images, but simply use random noise as the only feature.</p>

<p>Computing features is an inherently parallel task, and we are going to use a Redis job queue and a pool of workers. So, in another shell:</p>

<pre><code>./scripts/start_redis.sh</code></pre>

<p>Each chunk of jobs is executed by a client that downloads the images from their original URI’s, processes them, and stores the computed features to database.</p>

<pre><code>python vislab/feature.py compute --dataset=wikipaintings --features=noise --num_workers=6 --cpus_per_task=4</code></pre>

<p>After all the images have been processed, we write the data out to an HDF5 file for easier sharing and loading, and to a file that Vowpal Rabbit (our predictor) can read:</p>

<pre><code>python vislab/feature.py cache_to_h5 --dataset=wikipaintings --features=noise
python vislab/feature.py cache_to_vw --dataset=wikipaintings --features=noise</code></pre>

<p>You can always run <code>python vislab/feature.py compute -h</code> to read about the options.</p>

<h3 id="training_and_testing_prediction">Training and testing prediction</h3>

<p>TODO: talk about potenital pitfall: <code>gzcat</code> vs <code>zcat</code> on OS X.</p>

<p>The prediction task takes the feature to use as a flag, the MongoDB collection to store the results into, and the label to run on.</p>

<pre><code>python vislab/predict.py predict --dataset=wikipaintings --features=noise --collection_name=demo --prediction_label=&quot;style_*&quot; --num_workers=6</code></pre>

<p>This trains and tests on the Wikipaintings data, cross-validating parameters, and storing predictors to config-specified directory.</p>

<h3 id="visualizing_performance">Visualizing performance</h3>

<p>To visualize the prediction performance, we use a notebook. Take a look at the <code>wikipaintings results</code> notebook for an example. Running through it will generate publiction-ready figures and tables.</p>

<h3 id="applying_predictors_to_a_new_dataset">Applying predictors to a new dataset</h3>

<p>We can take the predictors learned on the Wikipaintings dataset and apply them to another dataset. In this demo, we will just run trained predictors on the same dataset:</p>

<pre><code>python vislab/predict.py predict --dataset=wikipaintings --source_dataset=wikipaintings --features=noise --collection_name=demo_predict_only --prediction_label=&quot;style_*&quot; --num_workers=6</code></pre>

<p>This is how predictors trained on one dataset can be applied to another dataset as “features.”</p>

<h3 id="hooking_up_a_new_dataset">Hooking up a new dataset</h3>

<p>If you get your data into a DataFrame format that the rest of the code expects, that’s all that’s really needed.</p>

<p>The required columns are ‘image_id’ (must be unique), ‘image_url’, and a column of whatever labels you care about. After this, add a couple of lines to <code>get_df_with_args()</code> in <code>dataset.py</code> as needed, and add another couple of lines to <code>fetch_image_filename_for_id</code> in <code>aphrodite/image.py</code> as needed.</p>

<p>For an example of a scraped dataset, take a look at <a href="https://github.com/sergeyk/vislab/blob/master/vislab/datasets/wikipaintings.py">vislab/datasets/wikipaintings.py</a>, or <a href="https://github.com/sergeyk/aphrodite/blob/master/aphrodite/flickr.py">aphrodite/flickr.py</a>.</p>

<h3 id="exploring_data_and_prediction_results_in_a_ui">Exploring data and prediction results in a UI</h3>

<p>Coming soon.</p>
    </section>
    <footer>
      <hr />
      <p>Developed by <a href="http://sergeykarayev.com">Sergey Karayev</a>.</p>
    </footer>
    <script>
    $(function() {
      return $("h2, h3, h4").each(function(i, el) {
        var id = $(el).attr('id');
        if (id) {
          return $(el).prepend($("<a />").attr("name", id).attr("href", "#" + id).html('#'));
        }
      });
    });
    </script>
  </body>
</html>
